vitb14
say
vit_base
Launced with slurm
world size, rank, gpu, device count: 1 0 0 1
| distributed init (rank 0): env://
git:
  sha: 62a7f9e8ab29bddd6c1b31e365b88b2a4b284acc, status: has uncommited changes, branch: master

arch: vit_base
batch_size_per_gpu: 1024
checkpoint_key: teacher
dist_url: env://
epochs: 500
evaluate: False
gpu: 0
local_rank: 0
lr: 0.0005
n_train: 1281167
n_val: 50000
num_labels: 1000
num_workers: 1
output_dir: /scratch/eo41/dino/evals/imagenet
patch_size: 14
pretrained_weights: /scratch/eo41/dino/models_vitb14/say_5fps_vitb14_checkpoint.pth
rank: 0
save_prefix: say_5fps_vitb14
train_data_path: /scratch/eo41/data/imagenet/imagenet_train_{000000..000001}.tar
val_data_path: /scratch/eo41/data/imagenet/imagenet_val_000000.tar
val_freq: 1
world_size: 1
Take key teacher in provided checkpoint dict
Pretrained weights found at /scratch/eo41/dino/models_vitb14/say_5fps_vitb14_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])
Model vit_base built.
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Data loaded with train and val imgs.
Epoch: [0]  [   0/1252]  eta: 4:24:08  lr: 0.000500  loss: 6.943655 (6.943655)  time: 12.658945  data: 10.264775  max mem: 13273
Epoch: [0]  [1251/1252]  eta: 0:00:06  lr: 0.000500  loss: 3.617038 (4.250470)  time: 5.926353  data: 4.893572  max mem: 14059
Epoch: [0] Total time: 2:09:17 (6.196446 s / it)
Averaged stats: lr: 0.000500  loss: 3.617038 (4.250470)
Test:  [ 0/49]  eta: 0:10:20  loss: 3.442476 (3.442476)  acc1: 31.054688 (31.054688)  acc5: 54.394531 (54.394531)  time: 12.658828  data: 11.591064  max mem: 14059
Test:  [48/49]  eta: 0:00:08  loss: 3.426685 (3.404688)  acc1: 31.835938 (32.650000)  acc5: 55.175781 (55.950000)  time: 8.087679  data: 7.018589  max mem: 14060
Test: Total time: 0:06:42 (8.204335 s / it)
* Acc@1 32.650 Acc@5 55.950 loss 3.405
Accuracy at epoch 0 of the network on test images: 32.6%
Max accuracy so far: 32.65%
Epoch: [1]  [   0/1252]  eta: 3:41:34  lr: 0.000500  loss: 3.585725 (3.585725)  time: 10.618633  data: 9.535803  max mem: 14060
Epoch: [1]  [1251/1252]  eta: 0:00:06  lr: 0.000500  loss: 3.313552 (3.399601)  time: 5.933296  data: 4.905632  max mem: 14060
Epoch: [1] Total time: 2:09:39 (6.213899 s / it)
Averaged stats: lr: 0.000500  loss: 3.313552 (3.399601)
Test:  [ 0/49]  eta: 0:10:19  loss: 3.081736 (3.081736)  acc1: 36.132812 (36.132812)  acc5: 61.132812 (61.132812)  time: 12.632985  data: 11.555395  max mem: 14060
Test:  [48/49]  eta: 0:00:08  loss: 3.160057 (3.135342)  acc1: 35.351562 (35.998000)  acc5: 59.277344 (59.848000)  time: 8.074345  data: 7.008568  max mem: 14060
Test: Total time: 0:06:42 (8.217637 s / it)
* Acc@1 35.998 Acc@5 59.848 loss 3.135
Accuracy at epoch 1 of the network on test images: 36.0%
Max accuracy so far: 36.00%
Epoch: [2]  [   0/1252]  eta: 3:34:51  lr: 0.000500  loss: 3.230290 (3.230290)  time: 10.296642  data: 9.221869  max mem: 14060
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 25910538 ON ga004 CANCELLED AT 2022-10-14T10:58:17 ***
slurmstepd: error: *** STEP 25910538.0 ON ga004 CANCELLED AT 2022-10-14T10:58:17 ***
