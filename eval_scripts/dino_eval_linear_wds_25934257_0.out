vitb14
say
vit_base
Launced with slurm
world size, rank, gpu, device count: 1 0 0 1
| distributed init (rank 0): env://
git:
  sha: 62a7f9e8ab29bddd6c1b31e365b88b2a4b284acc, status: has uncommited changes, branch: master

arch: vit_base
batch_size_per_gpu: 1024
checkpoint_key: teacher
dist_url: env://
epochs: 500
evaluate: False
gpu: 0
local_rank: 0
lr: 0.0005
n_train: 1281167
n_val: 50000
num_labels: 1000
num_workers: 1
output_dir: /scratch/eo41/dino/evals/imagenet
patch_size: 14
pretrained_weights: /scratch/eo41/dino/models_vitb14/say_5fps_vitb14_checkpoint.pth
rank: 0
save_prefix: say_5fps_vitb14
train_data_path: /scratch/eo41/data/imagenet/imagenet_train_{000000..000001}.tar
val_data_path: /scratch/eo41/data/imagenet/imagenet_val_000000.tar
val_freq: 1
world_size: 1
Take key teacher in provided checkpoint dict
Pretrained weights found at /scratch/eo41/dino/models_vitb14/say_5fps_vitb14_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])
Model vit_base built.
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Data loaded with train and val imgs.
Epoch: [0]  [   0/1252]  eta: 4:06:26  lr: 0.000500  loss: 6.934827 (6.934827)  time: 11.810074  data: 9.747259  max mem: 13273
Epoch: [0]  [1251/1252]  eta: 0:00:06  lr: 0.000500  loss: 3.621014 (4.258932)  time: 5.877326  data: 4.839015  max mem: 14059
Epoch: [0] Total time: 2:09:26 (6.203256 s / it)
Averaged stats: lr: 0.000500  loss: 3.621014 (4.258932)
Test:  [ 0/49]  eta: 0:10:00  loss: 3.325209 (3.325209)  acc1: 33.007812 (33.007812)  acc5: 57.812500 (57.812500)  time: 12.251873  data: 11.169404  max mem: 14059
Test:  [48/49]  eta: 0:00:08  loss: 3.385137 (3.390256)  acc1: 32.812500 (32.968000)  acc5: 55.957031 (56.280000)  time: 8.005139  data: 6.933495  max mem: 14060
Test: Total time: 0:06:40 (8.168640 s / it)
* Acc@1 32.968 Acc@5 56.280 loss 3.390
Accuracy at epoch 0 of the network on test images: 33.0%
Max accuracy so far: 32.97%
Epoch: [1]  [   0/1252]  eta: 3:26:17  lr: 0.000500  loss: 3.601199 (3.601199)  time: 9.886215  data: 8.815186  max mem: 14060
Epoch: [1]  [1251/1252]  eta: 0:00:06  lr: 0.000500  loss: 3.278374 (3.422936)  time: 5.920357  data: 4.889194  max mem: 14060
Epoch: [1] Total time: 2:09:04 (6.185390 s / it)
Averaged stats: lr: 0.000500  loss: 3.278374 (3.422936)
Test:  [ 0/49]  eta: 0:10:10  loss: 3.124314 (3.124314)  acc1: 35.156250 (35.156250)  acc5: 59.179688 (59.179688)  time: 12.450609  data: 11.375525  max mem: 14060
Test:  [48/49]  eta: 0:00:08  loss: 3.127411 (3.111906)  acc1: 36.425781 (36.766000)  acc5: 59.863281 (60.384000)  time: 7.972798  data: 6.905572  max mem: 14060
Test: Total time: 0:06:40 (8.173707 s / it)
* Acc@1 36.766 Acc@5 60.384 loss 3.112
Accuracy at epoch 1 of the network on test images: 36.8%
Max accuracy so far: 36.77%
Epoch: [2]  [   0/1252]  eta: 3:36:16  lr: 0.000500  loss: 3.317485 (3.317485)  time: 10.364651  data: 9.288437  max mem: 14060
slurmstepd: error: *** JOB 25934257 ON ga006 CANCELLED AT 2022-10-15T12:12:38 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 25934257.0 ON ga006 CANCELLED AT 2022-10-15T12:12:38 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
