vitb14
say
vit_base
Launced with slurm
world size, rank, gpu, device count: 1 0 0 1
| distributed init (rank 0): env://
git:
  sha: 62a7f9e8ab29bddd6c1b31e365b88b2a4b284acc, status: has uncommited changes, branch: master

arch: vit_base
batch_size_per_gpu: 1024
checkpoint_key: teacher
dist_url: env://
epochs: 500
evaluate: False
gpu: 0
local_rank: 0
lr: 0.0005
n_train: 1281167
n_val: 50000
num_labels: 1000
num_workers: 1
output_dir: /scratch/eo41/dino/evals/imagenet
patch_size: 14
pretrained_weights: /scratch/eo41/dino/models_vitb14/say_5fps_vitb14_checkpoint.pth
rank: 0
save_prefix: say_5fps_vitb14
train_data_path: /scratch/eo41/data/imagenet/imagenet_train_{000000..000001}.tar
val_data_path: /scratch/eo41/data/imagenet/imagenet_val_000000.tar
val_freq: 1
world_size: 1
Take key teacher in provided checkpoint dict
Pretrained weights found at /scratch/eo41/dino/models_vitb14/say_5fps_vitb14_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])
Model vit_base built.
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Data loaded with train and val imgs.
Epoch: [0]  [   0/1252]  eta: 4:08:00  lr: 0.000500  loss: 6.928358 (6.928358)  time: 11.885263  data: 9.975805  max mem: 13273
Epoch: [0]  [1251/1252]  eta: 0:00:06  lr: 0.000500  loss: 3.604473 (4.244037)  time: 5.820210  data: 4.794319  max mem: 14059
Epoch: [0] Total time: 2:09:38 (6.213237 s / it)
Averaged stats: lr: 0.000500  loss: 3.604473 (4.244037)
Test:  [ 0/49]  eta: 0:10:16  loss: 3.235927 (3.235927)  acc1: 34.667969 (34.667969)  acc5: 59.082031 (59.082031)  time: 12.572798  data: 11.506983  max mem: 14059
Test:  [48/49]  eta: 0:00:08  loss: 3.401427 (3.398020)  acc1: 32.226562 (32.608000)  acc5: 55.761719 (55.982000)  time: 8.027784  data: 6.960569  max mem: 14060
Test: Total time: 0:06:41 (8.199406 s / it)
* Acc@1 32.608 Acc@5 55.982 loss 3.398
Accuracy at epoch 0 of the network on test images: 32.6%
Max accuracy so far: 32.61%
Epoch: [1]  [   0/1252]  eta: 3:36:07  lr: 0.000500  loss: 3.633121 (3.633121)  time: 10.357274  data: 9.277036  max mem: 14060
Epoch: [1]  [1251/1252]  eta: 0:00:06  lr: 0.000500  loss: 3.277285 (3.421913)  time: 5.903812  data: 4.876318  max mem: 14060
Epoch: [1] Total time: 2:10:05 (6.234398 s / it)
Averaged stats: lr: 0.000500  loss: 3.277285 (3.421913)
Test:  [ 0/49]  eta: 0:10:04  loss: 3.032117 (3.032117)  acc1: 37.988281 (37.988281)  acc5: 62.109375 (62.109375)  time: 12.341595  data: 11.270605  max mem: 14060
Test:  [48/49]  eta: 0:00:08  loss: 3.127983 (3.117194)  acc1: 36.035156 (36.650000)  acc5: 60.253906 (60.210000)  time: 8.059996  data: 6.996254  max mem: 14060
Test: Total time: 0:06:41 (8.204034 s / it)
* Acc@1 36.650 Acc@5 60.210 loss 3.117
Accuracy at epoch 1 of the network on test images: 36.7%
Max accuracy so far: 36.65%
Epoch: [2]  [   0/1252]  eta: 3:37:39  lr: 0.000500  loss: 3.208713 (3.208713)  time: 10.430781  data: 9.356692  max mem: 14060
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 25917974 ON ga004 CANCELLED AT 2022-10-14T15:50:42 ***
slurmstepd: error: *** STEP 25917974.0 ON ga004 CANCELLED AT 2022-10-14T15:50:42 ***
