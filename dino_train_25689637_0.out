Launced with slurm
Launced with slurm
Launced with slurm
Launced with slurm
world size, rank, gpu, device count: 4 3 3 4
world size, rank, gpu, device count: 4 2 2 4
world size, rank, gpu, device count: 4 0 0 4
world size, rank, gpu, device count: 4 1 1 4
| distributed init (rank 0): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
git:
  sha: 237b6a9bfc30492be5ace81d8cb06356b3603d05, status: has uncommited changes, branch: master

arch: vit_base
batch_size_per_gpu: 128
clip_grad: 1.0
data_path: /scratch/eo41/data/saycam/A_5fps_300s_{000000..000002}.tar
dist_url: env://
epochs: 100
freeze_last_layer: 0
global_crops_scale: [0.2, 1.0]
gpu: 0
local_crops_number: 8
local_crops_scale: [0.05, 0.2]
local_rank: 0
lr: 0.0001
min_lr: 0.0001
momentum_teacher: 0.9995
norm_last_layer: True
num_workers: 8
optimizer: adamw
out_dim: 65536
output_dir: /scratch/eo41/dino/models_vitb16
patch_size: 16
print_freq: 5000
rank: 0
save_prefix: a_5fps_vitb16
saveckp_freq: 5000
seed: 1
teacher_temp: 0.04
use_bn_in_head: False
use_fp16: False
warmup_epochs: 0
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 0
weight_decay: 0.0
weight_decay_end: 0.0
world_size: 4
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:852: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:852: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:852: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:852: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Data loaded.
Student and Teacher are built: they are both vit_base network.
Loss, optimizer and schedulers ready.
Found checkpoint at /scratch/eo41/dino/models_vitb16/a_5fps_vitb16_checkpoint.pth
=> loaded 'student' from checkpoint '/scratch/eo41/dino/models_vitb16/a_5fps_vitb16_checkpoint.pth' with msg <All keys matched successfully>
=> loaded 'teacher' from checkpoint '/scratch/eo41/dino/models_vitb16/a_5fps_vitb16_checkpoint.pth' with msg <All keys matched successfully>
=> loaded 'optimizer' from checkpoint: '/scratch/eo41/dino/models_vitb16/a_5fps_vitb16_checkpoint.pth'
=> key 'fp16_scaler' not found in checkpoint: '/scratch/eo41/dino/models_vitb16/a_5fps_vitb16_checkpoint.pth'
=> loaded 'dino_loss' from checkpoint '/scratch/eo41/dino/models_vitb16/a_5fps_vitb16_checkpoint.pth' with msg <All keys matched successfully>
Starting DINO training !
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/scratch/eo41/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
Averaged stats: loss: 2.761488 (2.710230)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.467510 (2.481831)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.538837 (2.492001)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.386964 (2.461321)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.438620 (2.432815)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.442781 (2.407139)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.384057 (2.384637)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.330836 (2.370067)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.322359 (2.356726)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.360671 (2.338749)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.316360 (2.320027)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.244336 (2.303185)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.277905 (2.282317)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.207446 (2.270555)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.167407 (2.258211)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.181667 (2.240606)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.152958 (2.227720)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.216267 (2.213611)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.145462 (2.203772)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.171656 (2.192267)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.129577 (2.182440)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.204377 (2.165637)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.147779 (2.159913)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.151370 (2.147890)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.161103 (2.144735)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.098651 (2.131264)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
Averaged stats: loss: 2.117039 (2.121339)  lr: 0.000100 (0.000100)  wd: 0.000000 (0.000000)
slurmstepd: error: *** JOB 25689637 ON ga008 CANCELLED AT 2022-10-08T02:04:39 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 25689637.0 ON ga008 CANCELLED AT 2022-10-08T02:04:39 DUE TO TIME LIMIT ***
